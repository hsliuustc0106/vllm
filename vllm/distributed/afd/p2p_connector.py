# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright contributors to the vLLM project
import torch


from vllm.distributed.afd.afd_connector import (
    AFDConnectorBase,
    AFDConnectorMetadata,
)
from vllm.sequence import IntermediateTensors


class P2PConnector(AFDConnectorBase):
    def __init__(self, process_group) -> None:
        super().__init__(process_group)
        self.process_group = process_group

    def send_attn_output(
        self, hidden_states: torch.Tensor, metadata: AFDConnectorMetadata
    ):
        """
        This method will be called by the ATTN side.


        * To send the intermediate tensors generated by ATTN instances to FFN.
        """

        intermediate_tensors = IntermediateTensors(
            {
                "hidden_states": hidden_states,
            }
        )
        try:
            self.process_group.send_tensor_dict(
                intermediate_tensors.tensors,
                all_gather_group=None,
            )
        except Exception as e:
            raise RuntimeError(f"Communication error: {e}")

    def recv_attn_output(self) -> IntermediateTensors:
        """
        This method will be called by the FFN side.


        * To receive the intermediate tensors from ATTN.
        * And (Maybe) dispatch them from the receiver to other GPUs.
        """
        intermediate_tensors = self.process_group.recv_tensor_dict(
            all_gather_group=None,
        )
        return intermediate_tensors["hidden_states"]

    # -------------------------------------------------------------------------
    #                                attn <- ffn
    # -------------------------------------------------------------------------
    def send_ffn_output(
        self, hidden_states: torch.Tensor, metadata: AFDConnectorMetadata
    ):
        """
        This method will be called by the FFN side.


        * To send the intermediate tensors generated by FFN instances back to
            the sender (this should be the same GPU as it comes from)
        """
        intermediate_tensors = IntermediateTensors(
            {
                "hidden_states": hidden_states,
            }
        )
        self.process_group.send_tensor_dict(
            intermediate_tensors.tensors,
        )

    def recv_ffn_output(self) -> torch.Tensor:
        """
        This method will be called by the ATTN side.


        * To receive the MOE output intermediate tensors.
        * And (Maybe) dispatch them from the receiver to other GPUs.
            (this should be the same GPU as it comes from)
        """
        intermediate_tensors = self.process_group.recv_tensor_dict(
            all_gather_group=None,
        )
        return intermediate_tensors["hidden_states"]
