# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright contributors to the vLLM project
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional

import torch
from torch.distributed import ProcessGroup

from vllm.sequence import IntermediateTensors


@dataclass
class AFDConnectorMetadata:
    layer_idx: int  # Layer index for computation
    stage_idx: int  # Pipeline stage index
    seq_lens: list[int]  # Sequence lengths for each request
    dtype: torch.dtype  # Tensor data type
    device: torch.device  # Compute device
    request_id: Optional[str]  # Request identifier
    timestamp: Optional[float]  # Timestamp for debugging
    group: ProcessGroup  # communication domain
    topk_idx: Optional[torch.Tensor]  # indices token which expert to be sended
    topk_weights: Optional[torch.Tensor]  # the expert weights
    moe_expert_num: Optional[int]  # number of moe experts
    shared_expert_num: Optional[int]  # number of share experts
    handle: Optional[
        torch.Tensor
    ]  # the communication handle given by the recv_attn_output  function


class AFDConnectorBase(ABC):
    def __init__(self, process_group) -> None:
        super().__init__()
        self.process_group = process_group

    # -------------------------------------------------------------------
    #                         attn -> ffn
    # -------------------------------------------------------------------
    @abstractmethod
    def send_attn_output(
        self, hidden_states: torch.Tensor, metadata: AFDConnectorMetadata
    ):
        """
        This method will be called by the ATTN side.


        * To send the intermediate tensors generated by ATTN instances to FFN.
        """
        raise NotImplementedError

    @abstractmethod
    def recv_attn_output(self) -> torch.Tensor:
        """
        This method will be called by the FFN side.


        * To receive the intermediate tensors from ATTN.
        * And (Maybe) dispatch them from the receiver to other GPUs.
        """
        raise NotImplementedError

    # -------------------------------------------------------------------------
    #                                attn <- ffn
    # -------------------------------------------------------------------------
    @abstractmethod
    def send_ffn_output(
        self, hidden_states: torch.Tensor, metadata: AFDConnectorMetadata
    ):
        """
        This method will be called by the FFN side.


        * To send the intermediate tensors generated by FFN instances back to
            the sender (this should be the same GPU as it comes from)
        """
        raise NotImplementedError

    @abstractmethod
    def recv_ffn_output(self) -> torch.Tensor:
        """
        This method will be called by the ATTN side.


        * To receive the MOE output intermediate tensors.
        * And (Maybe) dispatch them from the receiver to other GPUs.
            (this should be the same GPU as it comes from)
        """
        raise NotImplementedError
